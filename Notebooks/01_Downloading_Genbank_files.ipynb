{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Extracting GenBank files from NCBI\n",
    "\n",
    "This notebook describes the process of downloading GenBank files for all genomic assemblies associated with each species of interest.\n",
    "\n",
    "This notebook refers to the Python script Extract_genomes_NCBI.py, included in the `Proteng` package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Note, that this notebook does not include the entirity of script code, but instead includes exerts to help illustrate the programme arcitecture and function. Speficially, the function `main`, which orchestrates the calling of functions to perform the overal operation of the script is excluded from this notebook, as well as logging and error checking.\n",
    "    \n",
    "    Additionally, in some instances sections of code have been removed and replaced by a comment to indicate the intent or function of the code, to enable a detailed description of the codes function at a more logical, and oppertune time.\n",
    "    \n",
    "    For the complete script, navigate to `Section1_Extracting_genomes_NCBI/Extract_genomes_NCBI.py` within the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    For the downloading of the GenBank files for the project, the following code was run at the command-line to initate the script run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating the script\n",
    "\n",
    "The script `Extract_genomes_NCBI.py` is written as a command-line programme and thus is mostly easily operated via the command-line. The standard structure of the command-line call to operate the script is:\n",
    "`python3 Extract_genomes_NCBI.py <user email> <options>`\n",
    "\n",
    "Multiple options are avilable to customise the operation of the script to the users needs. A full list of the available options are included in the README.\n",
    "\n",
    "A email address must be provided becuase this is a requirement to access the NCBI database remotely using `Entrez`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    For the downloading of the GenBank files for the project, the following code was run at the command-line:\n",
    "    python3 Extract_genomes_NCBI.py eemh1@st-andrews.ac.uk -i Species_list.txt -o 2020_05_31_GenBank_file_pulldown/ -l 2020_05_31_GB_file_download -v -d 2020_05_31_genome_dataframe.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **Note**: Before using the script `Extract_genomes_NCBI.py` ensure the documentation for Entrez has been read and understood, taking care to note expected practises laid out under  ['Frequency, Timing and Registration of E-utility URL Requests']( https://www.ncbi.nlm.nih.gov/books/NBK25497/)\n",
    "    \n",
    "    In total 695 GenBank files were downloaded in a single run of the script `Extract_genomes_NCBI.py` for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script input\n",
    "\n",
    "The script takes a plain text file as input, containing a list of the species of interst. Each line contains a unique species, identified by their scientific name or NCIB taxonomy ID (including the 'NCBI:txid' prefix).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    For the downloading of the GenBank files for the project, the file `Species_list.txt` within the `Section1_Extracting_genomes_NCBI` was used as the input file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from socket import timeout\n",
    "from typing import List, Optional\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from Bio import Entrez\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the input file and creating the dataframe\n",
    "\n",
    "The input file is either taken from STDIN or if a path was provided at the command-line, it is taken from where the path directs.\n",
    "\n",
    "Opening and parsing of the input file is performed by the function `parse_input_file`.\n",
    "\n",
    "Initially, it is checked that the path to the input file is valid and if not, the programme terminates. \n",
    "Afterwards, the file is opened, and parsed line-by-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_file(input_filename, logger, retries):\n",
    "    \n",
    "    # test path to input file exists, if not exit programme\n",
    "    if not input_filename.is_file():\n",
    "        # report to user and exit programme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the input file is retrievable, the file is parsed line-by-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if path to input file exists proceed\n",
    "    # parse input file\n",
    "    with open(input_filename) as file:\n",
    "        input_list = file.read().splitlines()\n",
    "\n",
    "    # Parse input, retrieving tax ID or scientific name as appropriate\n",
    "    line_count = 0\n",
    "    for line in tqdm(input_list, desc=\"Reading lines\"):\n",
    "        line_count += 1\n",
    "\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        line_data = parse_line(line, logger, line_count, retries)\n",
    "        all_species_data.append(line_data)\n",
    "\n",
    "    # create dataframe containing three columns: 'Genus', 'Species', 'NCBI Taxonomy ID'\n",
    "    species_table = pd.DataFrame(\n",
    "        all_species_data, columns=[\"Genus\", \"Species\", \"NCBI Taxonomy ID\"]\n",
    "    )\n",
    "    return species_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parse_line` coordinates the approrpiate calling of functions to retrieve the NCBI taxonomy ID if the scientific name is provided, retrieve the scientific name if the taxonomy ID is provided or perform no function if a comment is passed (indicated by the starting line character '#').\n",
    "\n",
    "The scientific name and taxonomy ID is stored as a single list for each species. This list contains the 3 elements:\n",
    "- The species 'Genus' name\n",
    "- The species 'Species' name\n",
    "- The species taxonomy ID (including the 'NCBI:txid' prefix).\n",
    "\n",
    "The list is returned by the function and added to the tuple `all_species_data` within the `parse_input_file` function. This creates a tuple, with each element containing the indentification data for a unique species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line, logger, line_count, retries):\n",
    "    \n",
    "    # For taxonomy ID retrieve scientific name\n",
    "    if line.startswith(\"NCBI:txid\"):\n",
    "        gs_name = get_genus_species_name(line[9:], logger, line_count, retries)\n",
    "        line_data = gs_name.split()\n",
    "        line_data.append(line)\n",
    "        \n",
    "    # For scientific name retrieve taxonomy ID\n",
    "    else:\n",
    "        tax_id = get_tax_id(line, logger, line_count, retries)\n",
    "        line_data = line.split()\n",
    "        line_data.append(tax_id)\n",
    "\n",
    "    return line_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific name and Taxonomy ID retrieval\n",
    "\n",
    "The retrieval of the scientific names and taxonomy ID from the NCBI Taxonomy databased is performed by the functions `get_genus_species_name` and `get_taxonomy_ID`.\n",
    "\n",
    "Each function calls to the NCBI Taxonomy database using entrez.\n",
    "\n",
    "If the scientific name or taxonomy ID was failed to be retrieved the `pandas` module recognised null value 'NA'.\n",
    "\n",
    "The retrieve of scientific names has the additional test to check if the 'name' passed to the function contains any number. If so, the null value is returned 'NA', the most common cause for this is inclusion of a taxonomy ID in the input file without the prefix 'NCBI:txid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genus_species_name(taxonomy_id, logger, line_number, retries):\n",
    "\n",
    "    # Retrieve scientific name\n",
    "    with entrez_retry(\n",
    "        logger, retries, Entrez.efetch, db=\"Taxonomy\", id=taxonomy_id, retmode=\"xml\"\n",
    "    ) as handle:\n",
    "        record = Entrez.read(handle)\n",
    "\n",
    "    # extract scientific name from record\n",
    "    try:\n",
    "        return record[0][\"ScientificName\"]\n",
    "\n",
    "    except IndexError:\n",
    "        # log error and return null value 'NA'\n",
    "        return \"NA\"\n",
    "\n",
    "\n",
    "def get_tax_id(genus_species, logger, line_number, retries):\n",
    "    # check for potential mistake in taxonomy ID prefix\n",
    "    if re.search(r\"\\d\", genus_species):\n",
    "        # log warning that numbers were found in line which was identified as a scientific name\n",
    "        return \"NA\"\n",
    "\n",
    "    else:\n",
    "        with entrez_retry(\n",
    "            logger, retries, Entrez.esearch, db=\"Taxonomy\", term=genus_species\n",
    "        ) as handle:\n",
    "            record = Entrez.read(handle)\n",
    "\n",
    "    # extract taxonomy ID from record\n",
    "    try:\n",
    "        return \"NCBI:txid\" + record[\"IdList\"][0]\n",
    "\n",
    "    except IndexError:\n",
    "        # log error\n",
    "        return \"NA\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataframe\n",
    "\n",
    "The `pandas` module is used to create a dataframe, within the `parse_input_file` function, with three columns:\n",
    "- Genus\n",
    "- Species\n",
    "- NCBI Taxonomy ID\n",
    "With a unique species per line.\n",
    "\n",
    "`Pandas` enables easier and faster storage and malipulation of dataframes than other table creating packages. More information is [available at](https://pandas.pydata.org/).\n",
    "\n",
    "The dataframe (`species_table`) is returned to the function `main`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    species_table = pd.DataFrame(\n",
    "        all_species_data, columns=[\"Genus\", \"Species\", \"NCBI Taxonomy ID\"]\n",
    "    )\n",
    "    return species_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving accession numbers\n",
    "\n",
    "The `pandas` module allows simultanous applying of a function to a dataframe, iterating over a given axis (row or column). This results in a 100-times faster processing of the dataframe than using a traditional Pythonic `for loop`. Therefore, the `pandas apply` function is used to retrieve the accession numbers of all genomic assemblies associated with each taxonomy ID within the `species_table` dataframe; this is completed by calling the function `get_accession_numbers`, and retrieved accession numbers are stored in a new column in the dataframe: `NCBI Accession Numbers`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    As before, if the retrieval of the asseccion numbers fails the null value 'NA' is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_table[\"NCBI Accession Numbers\"] = species_table.apply(\n",
    "    get_accession_numbers, args=(logger, args), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    If the taxonomy ID was failed to be retrieved previously (and was thus stored as 'NA') a null value of 'NA' will automatically be returned for accession numbers'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The `pandas apply` function passes a `pandas series` with each element (or cell within the dataframe) accessible via an index number, similar to accessing an element in a list.\n",
    "\n",
    "    The `apply function` is applied to each row of the dataframe thus each column is given its own index number, in order to access the appropriate data. In this case the index number assignments are:\n",
    "        df_row[0]: Genus\n",
    "        df_row[1]: Species\n",
    "        df_row[2]: Taxonomy ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval of assembly IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Entrez` is used to perform the call to the NCBI Assembly database. Owing to the taxonomy IDs for a species being stored within the NCBI Taxonomy database the `Entrez` function `elink` is used to retrieve the IDs of all genomic assemblies within the NCBI Assebmly database that are associated with the provided taxonomy ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accession_numbers(df_row, logger, args):\n",
    "        with entrez_retry(\n",
    "        logger,\n",
    "        args.retries,\n",
    "        Entrez.elink,\n",
    "        dbfrom=\"Taxonomy\",\n",
    "        id=df_row[2][9:],\n",
    "        db=\"Assembly\",\n",
    "        linkname=\"taxonomy_assembly\",\n",
    "    ) as assembly_number_handle:\n",
    "        assembly_number_record = Entrez.read(assembly_number_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This retrieves a list of IDs for all genomic assemblies associated with the taxonomy ID. To minimus the number of calls to the NCBI database, the list of IDs is posted as a single query to NCBI using `Entrez`.\n",
    "\n",
    "The web environment and query key are retrieved to facilitate the retrieval of the accession numbers of the identified genomic assemblies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # compile list of ids in suitable format for epost\n",
    "    id_post_list = str(\",\".join(assembly_id_list))\n",
    "    # Post all assembly IDs to Entrez-NCBI for downstream pulldown of accession numbers\n",
    "    epost_search_results = Entrez.read(\n",
    "        entrez_retry(logger, args.retries, Entrez.epost, \"Assembly\", id=id_post_list)\n",
    "    )\n",
    "\n",
    "    # Retrieve web environment and query key from Entrez epost\n",
    "    epost_webenv = epost_search_results[\"WebEnv\"]\n",
    "    epost_query_key = epost_search_results[\"QueryKey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval of accession numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Entrez` is used again to retrieval the accession numbers from the previously posted query. The accession numbers are collated into a single list, which is then converted into a string, this prevents the storage/appearance of list book ending sequare brackets `[]` within the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_accession_numbers_list = []\n",
    "\n",
    "    with entrez_retry(\n",
    "        logger,\n",
    "        args.retries,\n",
    "        Entrez.efetch,\n",
    "        db=\"Assembly\",\n",
    "        query_key=epost_query_key,\n",
    "        WebEnv=epost_webenv,\n",
    "        rettype=\"docsum\",\n",
    "        retmode=\"xml\",\n",
    "    ) as accession_handle:\n",
    "        accession_record = Entrez.read(accession_handle, validate=False)\n",
    "\n",
    "\n",
    "    # Extract accession numbers from document summary\n",
    "    for index_number in tqdm(\n",
    "        range(len(accession_record[\"DocumentSummarySet\"][\"DocumentSummary\"])),\n",
    "        desc=f\"Retrieving accessions ({df_row[2]})\",\n",
    "    ):\n",
    "        try:\n",
    "            new_accession_number = accession_record[\"DocumentSummarySet\"][\n",
    "                \"DocumentSummary\"\n",
    "            ][index_number][\"AssemblyAccession\"]\n",
    "            ncbi_accession_numbers_list.append(new_accession_number)\n",
    "\n",
    "        except IndexError:\n",
    "            # log error and return null value\n",
    "            return \"NA\"\n",
    "        \n",
    "        # GenBank file download enabling check\n",
    "\n",
    "        index_number += 1\n",
    "\n",
    "    # Process accession numbers into human readable list for dataframe\n",
    "    ncbi_accession_numbers = \", \".join(ncbi_accession_numbers_list)\n",
    "\n",
    "    return ncbi_accession_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading GenBank files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to add the retrieved accession number to the growing list of accessio numbers, a check is performed to see if the the downloading of the GenBank file (.gbff) associated with the genomic assembly entry is to be downloaded.\n",
    "\n",
    "If enabled, the downloading of the GenBank file is initated by called to the `get_genbank_files` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # If downloading of GenBank files is enabled, download Genbank files\n",
    "        if args.genbank is True:\n",
    "            get_genbank_files(\n",
    "                new_accession_number,\n",
    "                accession_record[\"DocumentSummarySet\"][\"DocumentSummary\"][index_number][\n",
    "                    \"AssemblyName\"\n",
    "                ],\n",
    "                logger,\n",
    "                args,\n",
    "            )\n",
    "            \n",
    "            \n",
    "def get_genbank_files(\n",
    "    accession_number,\n",
    "    assembly_name,\n",
    "    logger,\n",
    "    args,\n",
    "    suffix=\"genomic.gbff.gz\",\n",
    "):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloading of any file requires a URL address from which to download a file, and an output path to write the downloaded data too. The creation of both is orchestrated by the `get_genbank_files` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genbank_files(\n",
    "    accession_number,\n",
    "    assembly_name,\n",
    "    logger,\n",
    "    args,\n",
    "    suffix=\"genomic.gbff.gz\",\n",
    "):\n",
    "    \n",
    "    # compile url for download\n",
    "    genbank_url, filestem = compile_url(accession_number, assembly_name, logger, suffix)\n",
    "\n",
    "    # if downloaded file is not to be written to STDOUT, compile output path\n",
    "    if args.output is not sys.stdout:\n",
    "        out_file_path = args.output / \"_\".join([filestem.replace(\".\", \"_\"), suffix])\n",
    "    else:\n",
    "        out_file_path = args.output\n",
    "\n",
    "    # download GenBank file\n",
    "    download_file(\n",
    "        genbank_url, args, out_file_path, logger, accession_number, \"GenBank file\",\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the URL\n",
    "\n",
    "NCBI records can include a variety of escape characters within its records, but requires all escape characters to be written as underscores within its URLS. The `regular expression` module of Python is used to replace any escape charcters with underscords, prior to compiling the URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_url(\n",
    "    accession_number,\n",
    "    assembly_name,\n",
    "    logger,\n",
    "    suffix,\n",
    "    ftpstem=\"ftp://ftp.ncbi.nlm.nih.gov/genomes/all\",\n",
    "):\n",
    "   \n",
    "    # Extract assembly name, removing alterantive escape characters\n",
    "    escape_characters = re.compile(r\"[\\s/,#\\(\\)]\")\n",
    "    escape_name = re.sub(escape_characters, \"_\", assembly_name)\n",
    "\n",
    "    # compile filstem\n",
    "    filestem = \"_\".join([accession_number, escape_name])\n",
    "\n",
    "    # separate out filesteam into GCstem, accession number intergers and discarded\n",
    "    url_parts = tuple(filestem.split(\"_\", 2))\n",
    "\n",
    "    # separate identifying numbers from version number\n",
    "    sub_directories = \"/\".join(\n",
    "        [url_parts[1][i : i + 3] for i in range(0, len(url_parts[1].split(\".\")[0]), 3)]\n",
    "    )\n",
    "\n",
    "    # return url for downloading file\n",
    "    return (\n",
    "        \"{0}/{1}/{2}/{3}/{3}_{4}\".format(\n",
    "            ftpstem, url_parts[0], sub_directories, filestem, suffix\n",
    "        ),\n",
    "        filestem,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the GenBank \n",
    "\n",
    "The downloading of the GenBank file is initated with calling the `download_file` function.\n",
    "\n",
    "The URL connection is coordinated by the Python `urllib` module ([Documentation found here](https://docs.python.org/3/library/urllib.html).\n",
    "\n",
    "The Python `tqdm` module is also used provide a visual to log the download progress in the terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try URL connection\n",
    "    try:\n",
    "        response = urlopen(genbank_url, timeout=args.timeout)\n",
    "    except HTTPError, URLError, timeout:\n",
    "        # log error and exit downloading of GenBank file\n",
    "        return\n",
    "\n",
    "    if out_file_path.exists():\n",
    "        logger.warning(f\"Output file {out_file_path} exists, not downloading\")\n",
    "        \n",
    "    else:\n",
    "        # Download file\n",
    "        file_size = int(response.info().get(\"Content-length\"))\n",
    "        bsize = 1_048_576\n",
    "        \n",
    "        try:\n",
    "            with open(out_file_path, \"wb\") as out_handle:\n",
    "                # Using leave=False as this will be an internally-nested progress bar\n",
    "                with tqdm(\n",
    "                    total=file_size,\n",
    "                    leave=False,\n",
    "                    desc=f\"Downloading {accession_number} {file_type}\",\n",
    "                ) as pbar:\n",
    "                    while True:\n",
    "                        buffer = response.read(bsize)\n",
    "                        if not buffer:\n",
    "                            break\n",
    "                        pbar.update(len(buffer))\n",
    "                        out_handle.write(buffer)\n",
    "\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out the dataframe\n",
    "\n",
    "If the option to write out the dataframe to a file, rather than STDOUT, is enabled, the function `write_out_dataframe` will be called.\n",
    "\n",
    "The dataframe is written out as a .csv file (column-separated values format), to allow the opening and reading of the file by several packages including Microsoft Offic Excel, as well as easy parsing of the dataframe by other `pandas` using Python scripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_dataframe(species_table, logger, outdir, force, nodelete):\n",
    "\n",
    "    # Check if overwrite of existing directory will occur\n",
    "    logger.info(\"Checking if output directory for dataframe already exists\")\n",
    "    if outdir.exists():\n",
    "        if force is False:\n",
    "            logger.warning(\n",
    "                \"Specified directory for dataframe already exists.\\nExiting writing out dataframe.\"\n",
    "            )\n",
    "            return ()\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Specified directory for dataframe already exists.\\nForced overwritting enabled.\"\n",
    "            )\n",
    "\n",
    "    # Check if user included .csv file extension\n",
    "    if outdir.endswith(\".csv\"):\n",
    "        species_table.to_csv(outdir)\n",
    "    else:\n",
    "        out_df = outdir + \".csv\"\n",
    "        species_table.to_csv(out_df)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    For the downloading of GenBank files for the project, the following dataframe was written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f27d1ba6c49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/Section1_Extracting_Genomes/2020_05_31_genome_dataframe.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "input_path = ('/Section1_Extracting_Genomes/2020_05_31_genome_dataframe.csv')\n",
    "\n",
    "input_df = pd.read_csv(\n",
    "        input_path,\n",
    "        header=0,\n",
    "        names=[\"Genus\", \"Species\", \"NCBI Taxonomy ID\", \"NCBI Accession Numbers\"],\n",
    "    )\n",
    "\n",
    "print(input_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
